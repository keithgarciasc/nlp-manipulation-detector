{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a5bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and set up model for text classification using DistilBERT\n",
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45073bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 47671\n",
      "Test dataset size: 11918\n",
      "\n",
      "Sample items from train_dataset:\n",
      "Sample 0:\n",
      "  input_ids: shape=torch.Size([512]), values=[101, 1996, 2976, 3914, 2291, 2038, 15506, 2058, 2055, 1037]\n",
      "  attention_mask: shape=torch.Size([512]), values=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  labels: scalar=1\n",
      "----------------------------------------\n",
      "Sample 1:\n",
      "  input_ids: shape=torch.Size([512]), values=[101, 1030, 2142, 11079, 2001, 2081, 2197, 2251, 1012, 1045]\n",
      "  attention_mask: shape=torch.Size([512]), values=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  labels: scalar=1\n",
      "----------------------------------------\n",
      "Sample 2:\n",
      "  input_ids: shape=torch.Size([512]), values=[101, 2048, 18217, 1999, 2474, 18183, 3102, 1016, 1010, 1999]\n",
      "  attention_mask: shape=torch.Size([512]), values=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  labels: scalar=0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the custom dataset class used during saving\n",
    "class ManipulationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load the preprocessed datasets from disk\n",
    "# These were saved as full ManipulationDataset objects, so we must define the class first\n",
    "train_dataset = torch.load('../data/processed/tokenized/train_dataset.pt', weights_only=False)\n",
    "test_dataset = torch.load('../data/processed/tokenized/test_dataset.pt', weights_only=False)\n",
    "\n",
    "# Print the number of samples in each dataset\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "\n",
    "# Print a few sample items from the train dataset to verify structure and content\n",
    "print(\"\\nSample items from train_dataset:\")\n",
    "for i in range(3):\n",
    "    sample = train_dataset[i]\n",
    "    print(f\"Sample {i}:\")\n",
    "    for key, val in sample.items():\n",
    "        # Print shape and first few values for tensors\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            if val.dim() == 1:\n",
    "                print(f\"  {key}: shape={val.shape}, values={val[:10].tolist()}\")\n",
    "            else:\n",
    "                print(f\"  {key}: scalar={val.item()}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {val}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a4728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully:\n",
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained DistilBERT model for sequence classification\n",
    "# This initializes the model with a classification head suitable for binary tasks (2 labels by default)\n",
    "\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Print model summary to confirm it loaded correctly\n",
    "# This will show the architecture and number of parameters\n",
    "print(\"Model loaded successfully:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0e389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to compute evaluation metrics for binary classification\n",
    "def compute_metrics(pred):\n",
    "    # Extract true labels and predicted class indices\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    # Compute precision, recall, F1 score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    # Return metrics as a dictionary\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf267a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args created successfully:\n",
      "  output_dir = ./results\n",
      "  device = cuda:0\n",
      "  eval_strategy = IntervalStrategy.EPOCH\n",
      "  save_strategy = SaveStrategy.EPOCH\n",
      "  save_total_limit = 2\n",
      "  logging_strategy = IntervalStrategy.EPOCH\n",
      "  per_device_train_batch_size = 16\n",
      "  per_device_eval_batch_size = 16\n",
      "  num_train_epochs = 3\n"
     ]
    }
   ],
   "source": [
    "# Configure training parameters for Hugging Face's Trainer API\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",                     # Where to save model checkpoints and outputs\n",
    "    eval_strategy=\"epoch\",                       # Run evaluation at the end of each epoch (use `eval_strategy` for this transformers version)\n",
    "    save_strategy=\"epoch\",                      # Save model checkpoint at the end of each epoch\n",
    "    logging_dir=\"./logs\",                       # Directory for TensorBoard logs\n",
    "    per_device_train_batch_size=16,               # Training batch size per device\n",
    "    per_device_eval_batch_size=16,                # Evaluation batch size per device\n",
    "    num_train_epochs=3,                           # Total number of training epochs\n",
    "    weight_decay=0.01,                            # Weight decay for regularization\n",
    "    load_best_model_at_end=True,                  # Restore best model after training\n",
    "    metric_for_best_model=\"f1\",                 # Use F1 score to select best checkpoint\n",
    "    logging_strategy=\"epoch\",                   # Log metrics at the end of each epoch\n",
    "    save_total_limit=2                            # Keep only the 2 most recent checkpoints\n",
    ")\n",
    "\n",
    "# Quick verification prints so you can confirm the TrainingArguments object is configured\n",
    "print('training_args created successfully:')\n",
    "print('  output_dir =', training_args.output_dir)\n",
    "print('  device =', getattr(training_args, '_setup_devices', 'not-yet-initialized'))\n",
    "# eval_strategy attribute may be named eval_strategy or evaluation_strategy depending on version\n",
    "for attr in ('eval_strategy', 'evaluation_strategy', 'save_strategy', 'save_total_limit', 'logging_strategy', 'per_device_train_batch_size', 'per_device_eval_batch_size', 'num_train_epochs'):\n",
    "    if hasattr(training_args, attr):\n",
    "        print(f'  {attr} =', getattr(training_args, attr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da574e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8940' max='8940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8940/8940 6:04:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.246636</td>\n",
       "      <td>0.883789</td>\n",
       "      <td>0.872096</td>\n",
       "      <td>0.948894</td>\n",
       "      <td>0.908876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.263854</td>\n",
       "      <td>0.886055</td>\n",
       "      <td>0.875365</td>\n",
       "      <td>0.948482</td>\n",
       "      <td>0.910458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.369850</td>\n",
       "      <td>0.882950</td>\n",
       "      <td>0.895430</td>\n",
       "      <td>0.915236</td>\n",
       "      <td>0.905225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model has been trained and evaluated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='745' max='745' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [745/745 35:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "eval_loss: 0.263854056596756\n",
      "eval_accuracy: 0.8860547071656318\n",
      "eval_precision: 0.8753645239000888\n",
      "eval_recall: 0.948481934331639\n",
      "eval_f1: 0.9104576025319794\n",
      "eval_runtime: 2115.8831\n",
      "eval_samples_per_second: 5.633\n",
      "eval_steps_per_second: 0.352\n",
      "epoch: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Set up the Hugging Face Trainer with the model, training configuration, datasets, and evaluation metrics\n",
    "trainer = Trainer(\n",
    "    model=model,                          # The model to be trained (e.g., a fine-tuned transformer)\n",
    "    args=training_args,                   # Training arguments including batch size, epochs, logging, etc.\n",
    "    train_dataset=train_dataset,         # Dataset used for training\n",
    "    eval_dataset=test_dataset,           # Dataset used for evaluation during training\n",
    "    compute_metrics=compute_metrics      # Function to compute evaluation metrics such as accuracy or F1 score\n",
    ")\n",
    "\n",
    "# Notify that training is starting\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Begin the training process\n",
    "trainer.train()\n",
    "\n",
    "# Notify that training has completed\n",
    "print(\"Training complete. Model has been trained and evaluated.\")\n",
    "\n",
    "# Save the trained model's configuration and weights to the '../models/manipulation_detector_model' directory\n",
    "# This allows the model to be reloaded later for inference or further training\n",
    "model.save_pretrained(\"../models/manipulation_detector_model\")\n",
    "\n",
    "# Evaluate the model on the test dataset after training\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
