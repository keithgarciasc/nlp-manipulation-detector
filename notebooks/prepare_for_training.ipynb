{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d82b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import & Setup\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92b01e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 59589\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>manipulative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should I Get Bings</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which TV Female Friend Group Do You Belong In</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The New \"Star Wars: The Force Awakens\" Trailer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Vine Of New York On \"Celebrity Big Brothe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Couple Did A Stunning Photo Shoot With Their...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  manipulative\n",
       "0                                 Should I Get Bings             1\n",
       "1      Which TV Female Friend Group Do You Belong In             1\n",
       "2  The New \"Star Wars: The Force Awakens\" Trailer...             1\n",
       "3  This Vine Of New York On \"Celebrity Big Brothe...             1\n",
       "4  A Couple Did A Stunning Photo Shoot With Their...             1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and merge all datasets\n",
    "\n",
    "location_relative_path = \"../data/processed/cleaned/\"\n",
    "\n",
    "# Load each dataset\n",
    "df1 = pd.read_csv(location_relative_path + \"clickbait_data.txt\", sep=\"|\", skiprows=1, names=[\"text\", \"manipulative\"])\n",
    "df2 = pd.read_csv(location_relative_path + \"liar_train.txt\", sep=\"|\", skiprows=1, names=[\"text\", \"manipulative\"])\n",
    "df3 = pd.read_csv(location_relative_path + \"mentalmanip_con.txt\", sep=\"|\", skiprows=1, names=[\"text\", \"manipulative\"])\n",
    "df4 = pd.read_csv(location_relative_path + \"tweets.txt\", sep=\"|\", skiprows=1, names=[\"text\", \"manipulative\"])\n",
    "\n",
    "# Merge all into one DataFrame\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "# Convert label column to integer\n",
    "df['manipulative'] = df['manipulative'].astype(int)\n",
    "\n",
    "# Preview the first few rows\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66f55fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 59589\n",
      "Training samples: 47671\n",
      "Testing samples: 11918\n",
      "\n",
      "Sample training texts and labels:\n",
      "Text: The Federal Reserve system has presided over about a 95... percent decline in the U.S. dollar.\n",
      "Manipulative: 1\n",
      "---\n",
      "Text: @united reservation was made last July. I want to know why I wasn't reseated. This only happens on international itineraries\n",
      "Manipulative: 1\n",
      "---\n",
      "Text: Two explosions in La Paz kill 2, injure 6\n",
      "Manipulative: 0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['text'].tolist(), df['manipulative'].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Training samples: {len(train_texts)}\")\n",
    "print(f\"Testing samples: {len(test_texts)}\")\n",
    "\n",
    "# Preview a few training examples\n",
    "print(\"\\nSample training texts and labels:\")\n",
    "for i in range(3):\n",
    "    print(f\"Text: {train_texts[i]}\")\n",
    "    print(f\"Manipulative: {train_labels[i]}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e9278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training encodings keys: ['input_ids', 'attention_mask']\n",
      "Test encodings keys: ['input_ids', 'attention_mask']\n",
      "\n",
      "Sample tokenized training input_ids:\n",
      "Sample 1: [101, 1996, 2976, 3914, 2291, 2038, 15506, 2058, 2055, 1037]\n",
      "Sample 2: [101, 1030, 2142, 11079, 2001, 2081, 2197, 2251, 1012, 1045]\n",
      "Sample 3: [101, 2048, 18217, 1999, 2474, 18183, 3102, 1016, 1010, 1999]\n",
      "\n",
      "Sample attention masks:\n",
      "Sample 1: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Sample 2: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Sample 3: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize training and test texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Training encodings keys: {list(train_encodings.keys())}\")\n",
    "print(f\"Test encodings keys: {list(test_encodings.keys())}\")\n",
    "\n",
    "# Preview a few training samples\n",
    "print(\"\\nSample tokenized training input_ids:\")\n",
    "for i in range(3):\n",
    "    print(f\"Sample {i+1}: {train_encodings['input_ids'][i][:10]}\")\n",
    "\n",
    "print(\"\\nSample attention masks:\")\n",
    "for i in range(3):\n",
    "    print(f\"Sample {i+1}: {train_encodings['attention_mask'][i][:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4271e676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 47671\n",
      "Test dataset size: 11918\n",
      "\n",
      "Sample training items:\n",
      "input_ids: torch.Size([512]) | tensor([  101,  1996,  2976,  3914,  2291,  2038, 15506,  2058,  2055,  1037])\n",
      "attention_mask: torch.Size([512]) | tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels: 1\n",
      "---\n",
      "input_ids: torch.Size([512]) | tensor([  101,  1030,  2142, 11079,  2001,  2081,  2197,  2251,  1012,  1045])\n",
      "attention_mask: torch.Size([512]) | tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels: 1\n",
      "---\n",
      "input_ids: torch.Size([512]) | tensor([  101,  2048, 18217,  1999,  2474, 18183,  3102,  1016,  1010,  1999])\n",
      "attention_mask: torch.Size([512]) | tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels: 0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#Wrap as Torch Dataset\n",
    "class ManipulationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Instantiate datasets\n",
    "train_dataset = ManipulationDataset(train_encodings, train_labels)\n",
    "test_dataset = ManipulationDataset(test_encodings, test_labels)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Preview a few samples from train_dataset\n",
    "print(\"\\nSample training items:\")\n",
    "for i in range(3):\n",
    "    sample = train_dataset[i]\n",
    "    for key, val in sample.items():\n",
    "        if val.dim() > 0:\n",
    "            print(f\"{key}: {val.shape} | {val[:10]}\")\n",
    "        else:\n",
    "            print(f\"{key}: {val.item()}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f779060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Optional) Save Datasets\n",
    "\n",
    "tokenized_relative_path = f\"../data/processed/tokenized/\"\n",
    "\n",
    "torch.save(train_dataset, tokenized_relative_path + \"train_dataset.pt\")\n",
    "torch.save(test_dataset, tokenized_relative_path + \"test_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6bcd3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([512]) | tensor([  101,  1996,  2976,  3914,  2291,  2038, 15506,  2058,  2055,  1037])\n",
      "attention_mask: torch.Size([512]) | tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels: 1\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "loaded_test_dataset = torch.load(tokenized_relative_path + \"train_dataset.pt\", weights_only=False)\n",
    "\n",
    "# View a sample\n",
    "sample = loaded_test_dataset[0]\n",
    "for key, val in sample.items():\n",
    "    if val.dim() > 0:\n",
    "        print(f\"{key}: {val.shape} | {val[:10]}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val.item()}\")  # For scalar tensors like labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
